spring.http.encoding.charset=UTF-8
spring.http.encoding.enabled=true
spring.http.encoding.force=true
spring.messages.encoding=UTF-8
server.tomcat.uri-encoding=UTF-8
server.port=8083

info.app.version=@version@

spring.application.name=logmetric-server

management.health.mail.enabled=false
management.security.enabled=false
management.context-path=/manage
spring.metrics.export.delay-millis=10000


#engine 设置
logmetric.engine.workUnitConfigs[0].name=log
logmetric.engine.workUnitConfigs[0].fetcherBean=fetcher.kafka
logmetric.engine.workUnitConfigs[0].topics=framework.log,framework.jsonlog
logmetric.engine.workUnitConfigs[0].fetcherConfig.group.id=framework.log
logmetric.engine.workUnitConfigs[0].fetchThreads=4
logmetric.engine.workUnitConfigs[0].buffSize=100
logmetric.engine.workUnitConfigs[0].pumpBatchSize=500
logmetric.engine.workUnitConfigs[0].pipelineWidth=8
logmetric.engine.workUnitConfigs[0].handlerBeans=handler.kryoLog,handler.jsonlog

logmetric.engine.workUnitConfigs[1].name=metric
logmetric.engine.workUnitConfigs[1].fetcherBean=fetcher.kafka
logmetric.engine.workUnitConfigs[1].topics=framework.metric
logmetric.engine.workUnitConfigs[1].fetcherConfig.group.id=framework.metric
logmetric.engine.workUnitConfigs[1].fetchThreads=2
logmetric.engine.workUnitConfigs[1].buffSize=100
logmetric.engine.workUnitConfigs[1].pipelineWidth=4
logmetric.engine.workUnitConfigs[1].handlerBeans=handler.kairosdb

logmetric.engine.workUnitConfigs[2].name=failLog
logmetric.engine.workUnitConfigs[2].fetcherBean=fetcher.kafka
logmetric.engine.workUnitConfigs[2].topics=${logmetric.handler.failIndexLog.topic}
logmetric.engine.workUnitConfigs[2].fetcherConfig.group.id=framework.log.fail
logmetric.engine.workUnitConfigs[2].fetchThreads=1
logmetric.engine.workUnitConfigs[2].buffSize=100
logmetric.engine.workUnitConfigs[2].pipelineWidth=1
logmetric.engine.workUnitConfigs[2].handlerBeans=handler.failIndexLog


#fetcher 设置
spring.kafka.consumer.auto-commit-interval=5000
spring.kafka.consumer.auto-offset-reset=latest
spring.kafka.consumer.bootstrap-servers=logkafkafat01.along101.com:9092,logkafkafat02.along101.com:9092,logkafkafat03.along101.com:9092,logkafkafat04.along101.com:9092,logkafkafat05.along101.com:9092
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.fetch-max-wait=2000
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.max-poll-records=100
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.ByteArrayDeserializer

#handler 设置
#elasticsearch
logmetric.handler.kryoLog.index=logmetric
logmetric.handler.kryoLog.type=log
logmetric.handler.kryoLog.batchSize=5000
logmetric.handler.jsonlog.index=logmetric
logmetric.handler.jsonlog.type=log
logmetric.handler.jsonlog.batchSize=5000
logmetric.handler.failIndexLog.topic=framework.log.fail
logmetric.handler.failIndexLog.index=logmetric
logmetric.handler.failIndexLog.type=log
logmetric.handler.elasticsearch.cluster-name=gdslog
logmetric.handler.elasticsearch.cluster-nodes=localhost:9300
logmetric.handler.elasticsearch.properties.client.transport.sniff=true
logmetric.handler.elasticsearch.properties.xpack.security.user=logmetric:logmetric.write.pass

#写入es失败设置
spring.kafka.producer.acks=all
spring.kafka.producer.bootstrap-servers=${spring.kafka.consumer.bootstrap-servers}
spring.kafka.producer.batch-size=16384
spring.kafka.producer.retries=0
spring.kafka.producer.buffer-memory=33554432

#kairosdb 设置
logmetric.handler.kairosdb.url=http://localhost:8082

#eureka设置
eureka.instance.prefer-ip-address=true
eureka.client.serviceUrl.defaultZone=http://localhost:1113/eureka/
eureka.instance.instance-id=${spring.cloud.client.ipAddress}.${spring.application.name}.${server.port}
eureka.instance.metadata-map.management.context-path=${management.context-path}
eureka.instance.metadata-map.health.path=${management.context-path}/health
eureka.instance.health-check-url-path=${management.context-path}/health